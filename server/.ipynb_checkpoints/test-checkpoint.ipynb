{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e162f68a-ea6d-424d-b1b2-2731e0c846e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from text2vec import SentenceModel\n",
    "from flask import Flask\n",
    "from flask import render_template\n",
    "from flask import request\n",
    "from qdrant_client import QdrantClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93fabbe5-d40b-4275-afaa-6cfa2234205d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/tianlimin/vector based model/server\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "#os.chdir('/root/ChatBot/QA')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ea336b9-f590-4670-a110-b3203e6ca39c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-12-15 16:19:31.668\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtext2vec.sentence_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m80\u001b[0m - \u001b[34m\u001b[1mUse device: cpu\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# 加载向量化模型\n",
    "t2v_model = SentenceModel(\"../text2vec_cmed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31ec8c2c-d949-4c24-9ee2-b5d99a091a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入数据库key\n",
    "with open('key.txt','r') as f:\n",
    "    key = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c01f7af-7506-4248-994d-b86c3ce05e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 文本向量化\n",
    "def to_embeddings(text):\n",
    "    sentence_embeddings = t2v_model.encode(text)\n",
    "    return sentence_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd4e6648-8ad9-4fb1-a1e3-c9c366f73c4a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Loading checkpoint shards: 100%|██████████| 8/8 [00:11<00:00,  1.38s/it]\n"
     ]
    }
   ],
   "source": [
    "# 加载chatglm模型\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/Users/tianlimin/ChatGLM-6B/mode/chatglm-6b\", trust_remote_code=True)\n",
    "model = AutoModel.from_pretrained(\"/Users/tianlimin/ChatGLM-6B/mode/chatglm-6b\", trust_remote_code=True).half().to('mps')\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e769e94-073a-41ac-ac44-976bdf4013bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_glm(text,hsitory=[]):\n",
    "    response, history = model.chat(tokenizer, text, history=hsitory)\n",
    "    return response,history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "505e8642-9915-473f-bee9-cae594ee96ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The dtype of attention mask (torch.int64) is not bool\n",
      "/Users/tianlimin/.cache/huggingface/modules/transformers_modules/chatglm-6b/modeling_chatglm.py:460: UserWarning: MPS: no support for int64 for min_max, downcasting to a smaller data type (int32/float32). Native support for int64 has been added in macOS 13.3. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/mps/operations/ReduceOps.mm:621.)\n",
      "  cos, sin = self.rotary_emb(q1, seq_len=position_ids.max() + 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proprietor\n"
     ]
    }
   ],
   "source": [
    "print(ask_glm('As a customer, I want to view featured products on the homepage, so I can quickly see the best deals.')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2d5a38f5-3502-4e90-806b-f71c33661077",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt(question, answers):\n",
    "    q = '请用英文分析用户故事\\n' \n",
    "    for index, answer in enumerate(answers):\n",
    "        q += str(index + 1) + '. ' + str(answer['text']) + '\\n'\n",
    "    q = q+\"问题：%s || 答案：\" % question\n",
    "\n",
    "    return q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f6b6b16c-2abc-4f7b-9508-0c985a0f13fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(text):\n",
    "    client = QdrantClient(\n",
    "        url=\"https://9759a1d6-6cf2-4049-bd61-a5cb09ee44f3.us-east4-0.gcp.cloud.qdrant.io:6333\", \n",
    "        api_key=key,\n",
    "    )\n",
    "    collection_name = \"questions\"\n",
    "    \n",
    "    vector = to_embeddings(text)\n",
    "    \"\"\"\n",
    "    取搜索结果的前三个，如果想要更多的搜索结果，可以把limit设置为更大的值\n",
    "    \"\"\"\n",
    "    search_result = client.search(\n",
    "        collection_name=collection_name,\n",
    "        query_vector=vector.tolist(),\n",
    "        limit=3,\n",
    "        search_params={\"exact\": False, \"hnsw_ef\": 128}\n",
    "    )\n",
    "    answers = []\n",
    " \n",
    "    \"\"\"\n",
    "    每个匹配的相关摘要只取了前300个字符，如果想要更多的相关摘要，可以把这里的300改为更大的值\n",
    "    \"\"\"\n",
    "    for result in search_result:\n",
    "        if len(result.payload[\"text\"]) > 300:\n",
    "            summary = result.payload[\"text\"][:300]\n",
    "        else:\n",
    "            summary = result.payload[\"text\"]\n",
    "        answers.append({ \"text\": summary})\n",
    "    promptMessage=prompt(text, answers)\n",
    "    print(promptMessage)\n",
    "    response,history =  ask_glm(promptMessage)\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6812523b-0e9d-41cd-99b4-ff9a376039a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "请用英文分析用户故事\n",
      "1. 问题：\"As a customer, I want to view featured products on the homepage, so I can quickly see the best deals.\" || 答案：Total Score: 75 \n",
      "Overall, the user story has a solid score, indicating that it is well-defined, clear, and aligned with the user's role and desired outcome. It provides enough information\n",
      "2. 问题：\"As a customer, I want to view detailed product information, including images and specifications, so I can make informed decisions.\" || 答案：Total score：78 This user story appears well-structured, with a total score of 78. It effectively communicates the customer's need to view detailed product inf\n",
      "3. 问题：\"As a customer, I want to filter products by category, so I can narrow down my search.\" || 答案：Total score：79 This user story appears well-structured, with a total score of 79. It effectively communicates the customer's need to filter products by category, providing sufficient information for esti\n",
      "问题：As a customer, I want to view featured products on the homepage, so I can quickly see the best deals. || 答案：\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'⁇ 醒鍵詞： featured\\n\\n註解：這個詞表示“被選擇的”或“優秀的”，用於描述客戶在預覽主題页面上希望讓他們能夠快速找到的優秀产品。\\n\\n關鍵點：\\n\\n* 清晰地介紹了客戶希望讓他們在主題页面上找到的優秀产品。\\n* 強調了客戶希望讓他們能夠快速找到最優秀的選擇。\\n* 提供了足够的信息，以便設計師將選擇結果傳遞給客戶。\\n\\n優秀性：\\n\\n* 內容充足，清晰地描述了客戶希望在主題页面上找到的優秀产品。\\n* 強調了客戶希望讓他們能夠快速找到最優秀的選擇。\\n* 提供了設計師將選擇結果傳遞給客戶的充足信息。\\n\\n標題建議：\\n\\n* 網路獎勵\\n* 優秀的選擇\\n* 快速找到最優秀的產品\\n\\n綜合性分析：\\n\\n這個詞組和它的內容成功地描述了客戶希望在主題页面上找到的優秀產品，並且提供了設計師將選擇結果傳遞給客戶的充足信息。內容清晰、內容充足，並且強調了客戶希望讓他們能夠快速找到最優秀的選擇。因此，這個詞組在這個問題中得到了75分。'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query('As a customer, I want to view featured products on the homepage, so I can quickly see the best deals.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
